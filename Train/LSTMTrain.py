# -*- coding: utf-8 -*-
"""Stock_market_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/146Q9LqmRLZwVFbSNy8CHD-U2hdZnQcnW
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import joblib
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

from keras.models import Sequential
from keras.layers import Dense, LSTM,Dropout
from keras.callbacks import ModelCheckpoint,EarlyStopping

import warnings
warnings.filterwarnings("ignore")

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"]="3"
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

data=pd.read_csv("uploads/TSLA.csv")
# data.head()

# def check_df(dataframe,head=5):
#     print("Shape \n")
#     print(dataframe.shape)
#     print("Types \n")
#     print(dataframe.dtypes)
#     print("Head \n")
#     print(dataframe.head(head))
#     print("Tail \n")
#     print(dataframe.dtypes)
#     print("NA \n")
#     print(dataframe.isnull().sum())
#     print("Quantiles \n")
#     print(dataframe.quantile([0,0.5,0.50,0.95,0.99,1]).T)

# check_df(data)

data["Date"]=pd.to_datetime(data["Date"])

# data.head()

tesla_data=data[["Date","Close"]]

# tesla_data.head()

tesla_data.index=tesla_data["Date"]

# tesla_data

tesla_data.drop("Date",axis=1,inplace=True)

# tesla_data

result_data=tesla_data.copy()

# plt.figure(figsize=(12,6))
# plt.plot(tesla_data["Close"],color="blue");
# plt.ylabel("Stock Price")
# plt.title("Tesla Stock Price")
# plt.xlabel("Time")
# plt.show()

tesla_data=tesla_data.values

tesla_data[0:5]

tesla_data=tesla_data.astype("float32")

def split_data(dataframe,test_size):
    pos=int(round(len(dataframe)*(1-test_size)))
    train=dataframe[:pos]
    test=dataframe[pos:]
    return train,test,pos

train,test,pos=split_data(tesla_data,0.20)
# print(train.shape,test.shape)

scaler_train=MinMaxScaler(feature_range=(0,1))
train=scaler_train.fit_transform(train)
scaler_test=MinMaxScaler(feature_range=(0,1))
test=scaler_test.fit_transform(test)
train[0:5]

test[0:5]

def create_features(data,lookback):
    X,Y=[],[]
    for i in range(lookback,len(data)):
        X.append(data[i-lookback:i,0])
        Y.append(data[i,0])
    return np.array(X),np.array(Y)
lookback=20

X_train,y_train=create_features(train,lookback)

X_test,y_test=create_features(test,lookback)
# print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

y_test[0:5]

X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))
X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))
y_train=y_train.reshape(-1,1)
y_test=y_test.reshape(-1,1)
# print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

model=Sequential()
model.add(LSTM(units=50,
              activation="relu",
              input_shape=(X_train.shape[1],lookback)))
model.add(Dropout(0.2))
model.add(Dense(1))
# model.summary()

model.compile(loss="mean_squared_error",optimizer="adam")
callbacks=[EarlyStopping(monitor="val_loss",patience=3,verbose=1,mode="min"),
          ModelCheckpoint(filepath="mymodel.h5",monitor="val_loss",mode="min",
                         save_best_only=True,save_weights_only=False,verbose=1)]
history = model.fit(x=X_train,
                    y=y_train,
                    epochs=100,
                    batch_size=20,
                    validation_data=(X_test,y_test),
                    callbacks=callbacks,
                    shuffle=False)

model_filename= 'LSTM.model.joblib'
model_path= 'models/'+ model_filename
joblib.dump(model, model_path)
# plt.figure(figsize=(20,5))
# plt.subplot(1,2,2)
# plt.plot(history.history["loss"],label="Training Loss")
# plt.plot(history.history["val_loss"],label="Validation Loss")
# plt.legend(loc="upper right")
# plt.xlabel("Epoch",fontsize=16)
# plt.ylabel("Loss",fontsize=16)
# plt.ylim([0,max(plt.ylim())])
# plt.title("Training and Validation Loss",fontsize=16)
# plt.show()

# loss=model.evaluate(X_test,y_test,batch_size=20)

# print("\nTest loss:%.1f%%"%(100.0*loss))

# train_predict=model.predict(X_train)
# test_predict=model.predict(X_test)
# train_predict=scaler_train.inverse_transform(train_predict)
# test_predict=scaler_test.inverse_transform(test_predict)
# y_train=scaler_train.inverse_transform(y_train)
# y_test=scaler_test.inverse_transform(y_test)

# train_rmse=np.sqrt(mean_squared_error(y_train,train_predict))
# test_rmse=np.sqrt(mean_squared_error(y_test,test_predict,))
# print(f"Train RMSE:{train_rmse}")
# print(f"Test RMSE:{test_rmse}")

# train_prediction_data=result_data[lookback:pos]
# train_prediction_data["Predicted"]=train_predict
# train_prediction_data.head()

# test_prediction_data=result_data[pos+lookback:]
# test_prediction_data["Predicted"]=test_predict
# test_prediction_data.head()

# test_prediction_data['DIFFERENCE']=test_prediction_data['Close']-test_prediction_data['Predicted']
# summation1=test_prediction_data['DIFFERENCE'].sum()
# MAE=summation1/30
# MAE
# train_prediction_data['DIFFERENCE']=train_prediction_data['Close']-train_prediction_data['Predicted']
# summation_2=train_prediction_data['DIFFERENCE'].sum()
# MAE_2=summation_2/180
# x=test_prediction_data['Close'].mean()
# y=test_prediction_data['Predicted'].mean()
# difference=abs(x-y)
# difference
# error=difference/y
# error
# accuracy=1-error
# accuracy=accuracy*100
# accuracy

# plt.figure(figsize=(12,12))
# plt.plot(test_prediction_data["DIFFERENCE"],label="test_error")
# plt.plot(train_prediction_data["DIFFERENCE"],label="train_error")



# plt.figure(figsize=(14,5))
# plt.plot(result_data,label="Real Values")
# plt.plot(train_prediction_data["Predicted"],color="green",label="Train Predicted")
# plt.plot(test_prediction_data["Predicted"],color="red",label="Test Predicted")
# plt.xlabel("Time")
# plt.ylabel("Stock Values")
# plt.legend()
# plt.show()

